{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784',version=1,as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'categories',\n",
       " 'data',\n",
       " 'details',\n",
       " 'feature_names',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names',\n",
       " 'url']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data/255\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2325)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=[12, 6])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=[12, 6])</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=[12, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier([12,6])\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9382142857142857"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9720535714285714"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,classifier.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.55526431\n",
      "Iteration 2, loss = 0.24875543\n",
      "Iteration 3, loss = 0.19748636\n",
      "Iteration 4, loss = 0.16542102\n",
      "Iteration 5, loss = 0.14406268\n",
      "Iteration 6, loss = 0.12905269\n",
      "Iteration 7, loss = 0.11676783\n",
      "Iteration 8, loss = 0.10701810\n",
      "Iteration 9, loss = 0.09874034\n",
      "Iteration 10, loss = 0.09189202\n",
      "Iteration 11, loss = 0.08571248\n",
      "Iteration 12, loss = 0.07876260\n",
      "Iteration 13, loss = 0.07349092\n",
      "Iteration 14, loss = 0.06857428\n",
      "Iteration 15, loss = 0.06355597\n",
      "Iteration 16, loss = 0.05975951\n",
      "Iteration 17, loss = 0.05631568\n",
      "Iteration 18, loss = 0.05261830\n",
      "Iteration 19, loss = 0.04947755\n",
      "Iteration 20, loss = 0.04683983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=[50], max_iter=20, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=[50], max_iter=20, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=[50], max_iter=20, verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2 = MLPClassifier([50,],verbose=1,max_iter=20)\n",
    "classifier2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9697142857142858"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,classifier2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch.rand((4,28,28))[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 5],\n",
       "        [5, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matrix_power(torch.tensor(([1,1],[1,0])),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden_layer): Linear(in_features=10, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(MLP,self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size,128)\n",
    "        self.output = nn.Linear(128,1)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "model = MLP(input_size=10)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2982],\n",
       "        [0.2817],\n",
       "        [0.3615],\n",
       "        [0.2377],\n",
       "        [0.3588]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.rand((5,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01) #,momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NumberProductDataset(Dataset):\n",
    "    def __init__(self,data_range=(1,10)):\n",
    "        self.numbers = list(range(data_range[0],data_range[1]))\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        n1 = self.numbers[index]\n",
    "        n2 = self.numbers[index]+1\n",
    "        return (n1,n2),n1*n2\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.numbers)\n",
    "    \n",
    "\n",
    "dataset = NumberProductDataset(data_range=(0,11))\n",
    "\n",
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([2, 4, 0]), tensor([3, 5, 1])] tensor([ 6, 20,  0])\n",
      "[tensor([1, 3]), tensor([2, 4])] tensor([ 2, 12])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = NumberProductDataset(data_range=(0,5))\n",
    "dataloader = DataLoader(dataset,batch_size=3,shuffle=True)\n",
    "\n",
    "for (num_pairs,products) in dataloader:\n",
    "    print(num_pairs,products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberSumDataset(Dataset):\n",
    "    def __init__(self,data_range=(1,10)):\n",
    "        self.numbers = list(range(data_range[0],data_range[1]))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        n1 = float(self.numbers[index//len(self.numbers)])\n",
    "        n2 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([n1,n2]),torch.tensor([n1+n2])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.numbers)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NumberSumDataset(data_range=(0,100))\n",
    "dataloader = DataLoader(dataset,batch_size=100,shuffle=True)\n",
    "model=MLP(input_size=2)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Sum of Batch Losses = 305663.32942\n",
      "Epoch 1: Sum of Batch Losses = 5895.68135\n",
      "Epoch 2: Sum of Batch Losses = 1389.25043\n",
      "Epoch 3: Sum of Batch Losses = 136.75708\n",
      "Epoch 4: Sum of Batch Losses = 13.97746\n",
      "Epoch 5: Sum of Batch Losses = 8.63720\n",
      "Epoch 6: Sum of Batch Losses = 6.47426\n",
      "Epoch 7: Sum of Batch Losses = 4.94725\n",
      "Epoch 8: Sum of Batch Losses = 3.83149\n",
      "Epoch 9: Sum of Batch Losses = 3.04065\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss = 0.0\n",
    "    for n_p,sums in dataloader:\n",
    "        predictions = model(n_p)\n",
    "        ls=loss_function(predictions,sums)\n",
    "        ls.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss += ls.item()\n",
    "    print(\"Epoch {}: Sum of Batch Losses = {:.5f}\".format(epoch,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/codespace/.python/current/lib/python3.12/site-packages (4.48.3)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/codespace/.python/current/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'heart', 'genera', '##tive', 'ai']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('I heart Generative AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "model_name = 'textattack/bert-base-uncased-imdb'\n",
    "model = BertForSequenceClassification.from_pretrained(model_name,num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled\n",
      "output) e.g. for GLUE tasks.\n",
      "\n",
      "\n",
      "This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
      "library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
      "etc.)\n",
      "\n",
      "This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n",
      "Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n",
      "and behavior.\n",
      "\n",
      "Parameters:\n",
      "    config ([`BertConfig`]): Model configuration class with all the parameters of the model.\n",
      "        Initializing with a config file does not load the weights associated with the model, only the\n",
      "        configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n",
      "\u001b[0;31mInit docstring:\u001b[0m Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.python/current/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment : Positive (88.68%)\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('I love Generative AI',return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "    probabs = torch.nn.functional.softmax(outputs,dim=1)\n",
    "    predicted_class = torch.argmax(probabs)\n",
    "\n",
    "if predicted_class==1:\n",
    "    print(f'Sentiment : Positive ({probabs[0][1]*100:.2f}%)')\n",
    "else:\n",
    "    print(f'Sentimen : Negative ({probabs[0][0]*100: .2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Context-manager that disables gradient calculation.\n",
      "\n",
      "Disabling gradient calculation is useful for inference, when you are sure\n",
      "that you will not call :meth:`Tensor.backward()`. It will reduce memory\n",
      "consumption for computations that would otherwise have `requires_grad=True`.\n",
      "\n",
      "In this mode, the result of every computation will have\n",
      "`requires_grad=False`, even when the inputs have `requires_grad=True`.\n",
      "There is an exception! All factory functions, or functions that create\n",
      "a new Tensor and take a requires_grad kwarg, will NOT be affected by\n",
      "this mode.\n",
      "\n",
      "This context manager is thread local; it will not affect computation\n",
      "in other threads.\n",
      "\n",
      "Also functions as a decorator.\n",
      "\n",
      ".. note::\n",
      "    No-grad is one of several mechanisms that can enable or\n",
      "    disable gradients locally see :ref:`locally-disable-grad-doc` for\n",
      "    more information on how they compare.\n",
      "\n",
      ".. note::\n",
      "    This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.\n",
      "    If you want to disable forward AD for a computation, you can unpack\n",
      "    your dual tensors.\n",
      "\n",
      "Example::\n",
      "    >>> # xdoctest: +SKIP\n",
      "    >>> x = torch.tensor([1.], requires_grad=True)\n",
      "    >>> with torch.no_grad():\n",
      "    ...     y = x * 2\n",
      "    >>> y.requires_grad\n",
      "    False\n",
      "    >>> @torch.no_grad()\n",
      "    ... def doubler(x):\n",
      "    ...     return x * 2\n",
      "    >>> z = doubler(x)\n",
      "    >>> z.requires_grad\n",
      "    False\n",
      "    >>> @torch.no_grad()\n",
      "    ... def tripler(x):\n",
      "    ...     return x * 3\n",
      "    >>> z = tripler(x)\n",
      "    >>> z.requires_grad\n",
      "    False\n",
      "    >>> # factory function exception\n",
      "    >>> with torch.no_grad():\n",
      "    ...     a = torch.nn.Parameter(torch.rand(10))\n",
      "    >>> a.requires_grad\n",
      "    True\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.12/site-packages/torch/autograd/grad_mode.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?torch.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "WARNING: This review contains SPOILERS. Do not read if you don't want some points revealed to you before you watch the film.<br /><br />With a cast like this, you wonder whether or not the actors and actresses knew exactly what they were getting into. Did they see the script and say, `Hey, Close Encounters of the Third Kind was such a hit that this one can't fail.' Unfortunately, it does. Did they even think to check on the director's credentials..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "review_number = 42\n",
    "sample_review = dataset[\"train\"][review_number]\n",
    "\n",
    "display(HTML(sample_review[\"text\"][:450] + \"...\"))\n",
    "\n",
    "if sample_review[\"label\"] == 1:\n",
    "    print(\"Sentiment: Positive\")\n",
    "else:\n",
    "    print(\"Sentiment: Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=2)\n",
    "\n",
    "tokenier = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25000/25000 [01:41<00:00, 246.49 examples/s]\n",
      "Map: 100%|██████████| 25000/25000 [01:38<00:00, 254.70 examples/s]\n",
      "Map: 100%|██████████| 50000/50000 [03:19<00:00, 250.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenier(examples['text'],padding='max_length',truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments,Trainer\n\u001b[0;32m----> 3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m     12\u001b[0m     args \u001b[38;5;241m=\u001b[39m training_args,\n\u001b[1;32m     13\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m tokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m tokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m<string>:134\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[0m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/transformers/training_args.py:1772\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[0;32m-> 1772\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/transformers/training_args.py:2294\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2290\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   2292\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2293\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 2294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/transformers/utils/generic.py:62\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/transformers/training_args.py:2167\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 2167\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2168\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2169\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2170\u001b[0m         )\n\u001b[1;32m   2171\u001b[0m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[1;32m   2172\u001b[0m accelerator_state_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_configured_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=64,\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    eval_dataset = tokenized_datasets['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0070, 0.7033, 0.5358],\n",
      "        [0.1543, 0.5366, 0.3853],\n",
      "        [0.7967, 0.0500, 0.3223]])\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Fill in the missing parts labelled <MASK> with the appropriate code to complete the exercise.\n",
    "\n",
    "# Hint: Use torch.cuda.is_available() to check if GPU is available\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set the device to be used for the tensor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a tensor on the appropriate device\n",
    "my_tensor = torch.rand((3,3)).to(device)\n",
    "\n",
    "# Print the tensor\n",
    "print(my_tensor)\n",
    "\n",
    "# Check the previous cell\n",
    "\n",
    "assert my_tensor.device.type in {\"cuda\", \"cpu\"}\n",
    "assert my_tensor.shape == (3, 3)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyMLP(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with the appropriate code to complete the exercise.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    \"\"\"My Multilayer Perceptron (MLP)\n",
    "\n",
    "    Specifications:\n",
    "\n",
    "        - Input layer: 784 neurons\n",
    "        - Hidden layer: 128 neurons with ReLU activation\n",
    "        - Output layer: 10 neurons with softmax activation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784,128)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input to the second layer\n",
    "        x = (self.fc1(x))\n",
    "\n",
    "        # Apply ReLU activation\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Pass the result to the final layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "my_mlp = MyMLP()\n",
    "print(my_mlp)\n",
    "\n",
    "# Check your work here:\n",
    "\n",
    "\n",
    "# Check the number of inputs\n",
    "assert my_mlp.fc1.in_features == 784\n",
    "\n",
    "# Check the number of outputs\n",
    "assert my_mlp.fc2.out_features == 10\n",
    "\n",
    "# Check the number of nodes in the hidden layer\n",
    "assert my_mlp.fc1.out_features == 128\n",
    "\n",
    "# Check that my_mlp.fc1 is a fully connected layer\n",
    "assert isinstance(my_mlp.fc1, nn.Linear)\n",
    "\n",
    "# Check that my_mlp.fc2 is a fully connected layer\n",
    "assert isinstance(my_mlp.fc2, nn.Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with the appropriate code to complete the exercise.\n",
    "\n",
    "# Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (by convention we use the variable optimizer)\n",
    "optimizer = torch.optim.SGD(my_mlp.parameters(),lr=0.01)\n",
    "\n",
    "# Check\n",
    "\n",
    "assert isinstance(\n",
    "    loss_fn, nn.CrossEntropyLoss\n",
    "), \"loss_fn should be an instance of CrossEntropyLoss\"\n",
    "assert isinstance(optimizer, torch.optim.SGD), \"optimizer should be an instance of SGD\"\n",
    "assert optimizer.defaults[\"lr\"] == 0.01, \"learning rate should be 0.01\"\n",
    "assert optimizer.param_groups[0][\"params\"] == list(\n",
    "    my_mlp.parameters()\n",
    "), \"optimizer should be passed the MLP parameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0: 2.30101\n",
      "Epoch 0, batch 10: 2.30490\n",
      "Epoch 0, batch 20: 2.30479\n",
      "Epoch 1, batch 0: 2.30265\n",
      "Epoch 1, batch 10: 2.29463\n",
      "Epoch 1, batch 20: 2.30482\n",
      "Epoch 2, batch 0: 2.30415\n",
      "Epoch 2, batch 10: 2.30648\n",
      "Epoch 2, batch 20: 2.30480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with the appropriate code to complete the exercise.\n",
    "\n",
    "def fake_training_loaders():\n",
    "    for _ in range(30):\n",
    "        yield torch.randn(64, 784), torch.randint(0, 10, (64,))\n",
    "\n",
    "\n",
    "for epoch in range(3):\n",
    "    # Create a training loop\n",
    "    for i, data in enumerate(fake_training_loaders()):\n",
    "        # Every data instance is an input + label pair\n",
    "        x, y = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (predictions)\n",
    "        y_pred = my_mlp(x)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, batch {i}: {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "\n",
    "assert abs(loss.item() - 2.3) < 0.1, \"the loss should be around 2.3 with random data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with the appropriate code to complete the exercise.\n",
    "\n",
    "# Get the model and tokenizer\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "\n",
    "def get_prediction(review):\n",
    "    \"\"\"Given a review, return the predicted sentiment\"\"\"\n",
    "\n",
    "    # Tokenize the review\n",
    "    # (Get the response as tensors and not as a list)\n",
    "    inputs = tokenizer(review,return_tensors='pt')\n",
    "\n",
    "    # Perform the prediction (get the logits)\n",
    "    outputs = pt_model(**inputs)\n",
    "\n",
    "    # Get the predicted class (corresponding to the highest logit)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    return \"positive\" if predictions.item() == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This movie is not so great :(\n",
      "Sentiment: negative\n",
      "Review: This movie rocks!\n",
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "review = \"This movie is not so great :(\"\n",
    "\n",
    "print(f\"Review: {review}\")\n",
    "print(f\"Sentiment: {get_prediction(review)}\")\n",
    "\n",
    "assert get_prediction(review) == \"negative\", \"The prediction should be negative\"\n",
    "\n",
    "\n",
    "review = \"This movie rocks!\"\n",
    "\n",
    "print(f\"Review: {review}\")\n",
    "print(f\"Sentiment: {get_prediction(review)}\")\n",
    "\n",
    "assert get_prediction(review) == \"positive\", \"The prediction should be positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace <MASK> with the appropriate code\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the test split of the imdb dataset\n",
    "dataset = load_dataset('imdb',split='test')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 0,\n",
      " 'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV '\n",
      "         'are usually underfunded, under-appreciated and misunderstood. I '\n",
      "         'tried to like this, I really did, but it is to good TV sci-fi as '\n",
      "         'Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap '\n",
      "         \"cardboard sets, stilted dialogues, CG that doesn't match the \"\n",
      "         'background, and painfully one-dimensional characters cannot be '\n",
      "         \"overcome with a 'sci-fi' setting. (I'm sure there are those of you \"\n",
      "         \"out there who think Babylon 5 is good sci-fi TV. It's not. It's \"\n",
      "         'clichéd and uninspiring.) While US viewers might like emotion and '\n",
      "         'character development, sci-fi is a genre that does not take itself '\n",
      "         'seriously (cf. Star Trek). It may treat important issues, yet not as '\n",
      "         \"a serious philosophy. It's really difficult to care about the \"\n",
      "         'characters here as they are not simply foolish, just missing a spark '\n",
      "         'of life. Their actions and reactions are wooden and predictable, '\n",
      "         \"often painful to watch. The makers of Earth KNOW it's rubbish as \"\n",
      "         'they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise '\n",
      "         \"people would not continue watching. Roddenberry's ashes must be \"\n",
      "         'turning in their orbit as this dull, cheap, poorly edited (watching '\n",
      "         'it without advert breaks really brings this home) trudging Trabant '\n",
      "         'of a show lumbers into space. Spoiler. So, kill off a main '\n",
      "         'character. And then bring him back as another actor. Jeeez! Dallas '\n",
      "         'all over again.'}\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "assert isinstance(dataset, Dataset), \"The dataset should be a Dataset object\"\n",
    "assert set(dataset.features.keys()) == {\n",
    "    \"label\",\n",
    "    \"text\",\n",
    "}, \"The dataset should have a label and a text feature\"\n",
    "\n",
    "# Show the first example\n",
    "pprint(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I got Monster Man in a box set of three films where I mainly wanted the other tw \n",
      "... ous, often gnarly splatter comedy that should endear itself to fans of the same.\n",
      "Label: positive\n",
      "Prediction: positive\n",
      "\n",
      "Review: Five minutes in, i started to feel how naff this was looking, you've got a compl \n",
      "... for anyone who likes their horror with several side orders of gore and attitude.\n",
      "Label: positive\n",
      "Prediction: positive\n",
      "\n",
      "Review: I caught this movie on the Sci-Fi channel recently. It actually turned out to be \n",
      "... e more than passable for the horror/slasher buff. Definitely worth checking out.\n",
      "Label: positive\n",
      "Prediction: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with the appropriate code\n",
    "\n",
    "# Get the last 3 reviews\n",
    "reviews = dataset[\"text\"][-3:]\n",
    "\n",
    "# Get the last 3 labels\n",
    "labels = dataset[\"label\"][-3:]\n",
    "\n",
    "# Check\n",
    "for review, label in zip(reviews, labels):\n",
    "    # Let's use your get_prediction function to get the sentiment\n",
    "    # of the review!\n",
    "    prediction = get_prediction(review)\n",
    "\n",
    "    print(f\"Review: {review[:80]} \\n... {review[-80:]}\")\n",
    "    print(f'Label: {\"positive\" if label else \"negative\"}')\n",
    "    print(f\"Prediction: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (2.2.0)\n",
      "Collecting torch==2.6.0 (from torchvision)\n",
      "  Downloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (2024.2.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch==2.6.0->torchvision)\n",
      "  Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n",
      "Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading triton-3.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cpu\n",
      "    Uninstalling torch-2.5.1+cpu:\n",
      "      Successfully uninstalled torch-2.5.1+cpu\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.6.0 torchvision-0.21.0 triton-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[1;32m      3\u001b[0m mobilenet_v3_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mmobilenet_v3_small(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/torchvision/_meta_registrations.py:25\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroi_align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/torchvision/_meta_registrations.py:18\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(fn):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[38;5;241m.\u001b[39m_has_ops():\n\u001b[1;32m     19\u001b[0m         get_meta_lib()\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision, op_name), overload_name), fn)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "mobilenet_v3_model = models.mobilenet_v3_small(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN THE FOLLOWING USING CUDA\n",
    "\n",
    "STARTING FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion-MNIST dataset\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def load_data(batch_size, data_dir=\"data\"):\n",
    "    \"\"\"Load the Fashion-MNIST dataset.\"\"\"\n",
    "\n",
    "    # Define transforms to normalize the data\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "    )\n",
    "\n",
    "    # Download and load the training data\n",
    "    trainset = datasets.FashionMNIST(\n",
    "        data_dir, download=True, train=True, transform=transform\n",
    "    )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Download and load the test data\n",
    "    testset = datasets.FashionMNIST(\n",
    "        data_dir, download=True, train=False, transform=transform\n",
    "    )\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "trainloader, testloader = load_data(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some helper functions to helps with the labels\n",
    "def get_class_names():\n",
    "    \"\"\"Return the list of classes in the Fashion-MNIST dataset.\"\"\"\n",
    "    return [\n",
    "        \"T-shirt/top\",\n",
    "        \"Trouser\",\n",
    "        \"Pullover\",\n",
    "        \"Dress\",\n",
    "        \"Coat\",\n",
    "        \"Sandal\",\n",
    "        \"Shirt\",\n",
    "        \"Sneaker\",\n",
    "        \"Bag\",\n",
    "        \"Ankle boot\",\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_class_name(class_index):\n",
    "    \"\"\"Return the class name for the given index.\"\"\"\n",
    "    return get_class_names()[class_index]\n",
    "\n",
    "\n",
    "def get_class_index(class_name):\n",
    "    \"\"\"Return the class index for the given name.\"\"\"\n",
    "    return get_class_names().index(class_name)\n",
    "\n",
    "\n",
    "for class_index in range(10):\n",
    "    print(f\"class_index={class_index}, class_name={get_class_name(class_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 10 images from the training set with their labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# function to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()  # convert from tensor to numpy array\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # transpose dimensions\n",
    "\n",
    "\n",
    "images, labels = next(iter(trainloader))  # get the first batch\n",
    "\n",
    "# show images with labels\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "plot_size = 10\n",
    "\n",
    "for idx in np.arange(plot_size):\n",
    "    ax = fig.add_subplot(2, plot_size // 2, idx + 1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(get_class_name(int(labels[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained MobileNetV3 and inspect its structure\n",
    "import torchvision.models as models\n",
    "\n",
    "mobilenet_v3_model = models.mobilenet_v3_small(pretrained=True)\n",
    "print(mobilenet_v3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> to complete this code cell\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# Define a model class that extends the nn.Module class\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "\n",
    "        # Load the pre-trained MobileNetV3 (Small) architecture\n",
    "        self.model = models.mobilenet_v3_small(pretrained=True)\n",
    "\n",
    "        # Replace the last fully-connected layer with a new one of the right size\n",
    "        self.model.classifier[3] = nn.Linear(1024,10)\n",
    "\n",
    "        # Freeze all the weights of the network except for the last fully-connected layer\n",
    "        self.freeze()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert 1x28x28 input tensor to 3x28x28 tensor, to convert it to a color image\n",
    "        x = x.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Resize the input to 224x224, since MobileNetV3 (Small) expects images of that size\n",
    "        if x.shape[2:] != (224, 224):\n",
    "            x = F.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Forward pass\n",
    "        return self.model(x)\n",
    "\n",
    "    def freeze(self):\n",
    "        # Freeze all the weights of the network except for the last fully-connected layer\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze the final layer\n",
    "        for param in self.model.classifier[3].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfreeze(self):\n",
    "        # Unfreeze all the weights of the network\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "# Create an instance of the MobileNetV3 model\n",
    "model = MobileNetV3()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> to complete this code cell\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.002)\n",
    "\n",
    "# Set the device as GPU, MPS, or CPU according to availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> to complete this code cell\n",
    "\n",
    "# Create a PyTorch training loop\n",
    "\n",
    "model = model.to(device)  # Move the model weights to the device\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for batch_num, (images, labels) in enumerate(trainloader):\n",
    "        # Move tensors to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero out the optimizer's gradient buffer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate the loss and perform backprop\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss for every 100th iteration\n",
    "        if (batch_num) % 100 == 0:\n",
    "            print(\n",
    "                \"Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}\".format(\n",
    "                    epoch + 1, epochs, batch_num + 1, len(trainloader), loss.item()\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> to complete this code cell\n",
    "\n",
    "# Print the loss and accuracy on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "loss = 0\n",
    "\n",
    "for images, labels in testloader:\n",
    "    # Move tensors to the configured device\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss += loss_fn(i)\n",
    "\n",
    "    # torch.max return both max and argmax. We get the argmax here.\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(\n",
    "    \"Test Accuracy of the model on the test images: {} %\".format(100 * correct / total)\n",
    ")\n",
    "print(\"Test Loss of the model on the test images: {}\".format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a few examples of correct and incorrect predictions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the first batch of images and labels\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "# Move tensors to the configured device\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Plot the images with labels, at most 10\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "for idx in np.arange(min(10, len(images))):\n",
    "    ax = fig.add_subplot(2, 10 // 2, idx + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images.cpu()[idx]))\n",
    "    ax.set_title(\n",
    "        \"{} ({})\".format(get_class_name(predicted[idx]), get_class_name(labels[idx])),\n",
    "        color=(\"green\" if predicted[idx] == labels[idx] else \"red\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ends Here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 5574/5574 [00:00<00:00, 276970.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=0, sms=Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label=0, sms=Ok lar... Joking wif u oni...\n",
      "\n",
      "label=1, sms=Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find a spam dataset at https://huggingface.co/datasets and load it using the datasets library\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sms_spam\", split=[\"train\"])[0]\n",
    "\n",
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry[\"sms\"]\n",
    "    label = entry[\"label\"]\n",
    "    print(f\"label={label}, sms={sms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=NOT SPAM, sms=Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label=NOT SPAM, sms=Ok lar... Joking wif u oni...\n",
      "\n",
      "label=SPAM, sms=Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convenient dictionaries to convert between labels and ids\n",
    "id2label = {0: \"NOT SPAM\", 1: \"SPAM\"}\n",
    "label2id = {\"NOT SPAM\": 0, \"SPAM\": 1}\n",
    "\n",
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry[\"sms\"]\n",
    "    label_id = entry[\"label\"]\n",
    "    print(f\"label={id2label[label_id]}, sms={sms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (label=NOT SPAM) -> Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "1 (label=NOT SPAM) -> Ok lar... Joking wif u oni...\n",
      "\n",
      "2 (label=SPAM) -> Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's start with this helper function that will help us format sms messages\n",
    "# for the LLM.\n",
    "def get_sms_messages_string(dataset, item_numbers, include_labels=False):\n",
    "    sms_messages_string = \"\"\n",
    "    for item_number, entry in zip(item_numbers, dataset.select(item_numbers)):\n",
    "        sms = entry[\"sms\"]\n",
    "        label_id = entry[\"label\"]\n",
    "\n",
    "        if include_labels:\n",
    "            sms_messages_string += (\n",
    "                f\"{item_number} (label={id2label[label_id]}) -> {sms}\\n\"\n",
    "            )\n",
    "        else:\n",
    "            sms_messages_string += f\"{item_number} -> {sms}\\n\"\n",
    "\n",
    "    return sms_messages_string\n",
    "\n",
    "\n",
    "print(get_sms_messages_string(dataset, range(3), include_labels=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following SMS messages, classify them as spam or not spam by responding in a JSON format :7 -> As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "\n",
      "8 -> WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "\n",
      "9 -> Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n",
      "10 -> I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
      "\n",
      "11 -> SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
      "\n",
      "12 -> URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
      "\n",
      "13 -> I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
      "\n",
      "14 -> I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with your code\n",
    "\n",
    "# Get a few messages and format them as a string\n",
    "sms_messages_string = get_sms_messages_string(dataset, range(7, 15))\n",
    "\n",
    "# Construct a query to send to the LLM including the sms messages.\n",
    "# Ask it to respond in JSON format.\n",
    "query = f'Given the following SMS messages, classify them as spam or not spam by responding in a JSON format :{sms_messages_string}'\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your LLMs response\n",
    "\n",
    "response = {\n",
    "  \"7\": \"not spam\",\n",
    "  \"8\": \"spam\",\n",
    "  \"9\": \"spam\",\n",
    "  \"10\": \"not spam\",\n",
    "  \"11\": \"spam\",\n",
    "  \"12\": \"spam\",\n",
    "  \"13\": \"not spam\",\n",
    "  \"14\": \"not spam\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Estimate the accuracy of your classifier by comparing your responses to the labels in the dataset\n",
    "\n",
    "\n",
    "def get_accuracy(response, dataset, original_indices):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for entry_number, prediction in response.items():\n",
    "        if int(entry_number) not in original_indices:\n",
    "            continue\n",
    "\n",
    "        label_id = dataset[int(entry_number)][\"label\"]\n",
    "        label = id2label[label_id]\n",
    "\n",
    "        # If the prediction from the LLM matches the label in the dataset\n",
    "        # we increment the number of correct predictions.\n",
    "        # (Since LLMs do not always produce the same output, we use the\n",
    "        # lower case version of the strings for comparison)\n",
    "        if prediction.lower() == label.lower():\n",
    "            correct += 1\n",
    "\n",
    "        # increment the total number of predictions\n",
    "        total += 1\n",
    "\n",
    "    try:\n",
    "        accuracy = correct / total\n",
    "    except ZeroDivisionError:\n",
    "        print(\"No matching results found!\")\n",
    "        return\n",
    "\n",
    "    return round(accuracy, 2)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {get_accuracy(response, dataset, range(7, 15))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the following SMS messages, using the labels for some messages, generate the spam and non-spam classifications of all the messages by responding in a JSON format:\n",
      "54 (label=SPAM) -> SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect? End? Reply END SPTV\n",
      "\n",
      "55 (label=NOT SPAM) -> Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;\n",
      "\n",
      "56 (label=SPAM) -> Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out! \n",
      "\n",
      "57 (label=NOT SPAM) -> Sorry, I'll call later in meeting.\n",
      "\n",
      "58 (label=NOT SPAM) -> Tell where you reached\n",
      "\n",
      "59 (label=NOT SPAM) -> Yes..gauti and sehwag out of odi series.\n",
      "\n",
      "\n",
      "7 -> As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "\n",
      "8 -> WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "\n",
      "9 -> Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n",
      "10 -> I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
      "\n",
      "11 -> SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
      "\n",
      "12 -> URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
      "\n",
      "13 -> I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
      "\n",
      "14 -> I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with your code that constructs a query to send to the LLM\n",
    "\n",
    "# Get a few labelled messages and format them as a string\n",
    "sms_messages_string_w_labels = get_sms_messages_string(\n",
    "    dataset, range(54, 60), include_labels=True\n",
    ")\n",
    "\n",
    "# Get a few unlabelled messages and format them as a string\n",
    "sms_messages_string_no_labels = get_sms_messages_string(dataset, range(7, 15))\n",
    "\n",
    "\n",
    "# Construct a query to send to the LLM including the labelled messages\n",
    "# as well as the unlabelled messages. Ask it to respond in JSON format\n",
    "query = f\"From the following SMS messages, using the labels for some messages, generate the spam and non-spam classifications of all the messages by responding in a JSON format:\\n{sms_messages_string_w_labels}\\n{sms_messages_string_no_labels}\"\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with your LLMs response\n",
    "\n",
    "response = {\n",
    "  \"54\": \"spam\",\n",
    "  \"55\": \"not spam\",\n",
    "  \"56\": \"spam\",\n",
    "  \"57\": \"not spam\",\n",
    "  \"58\": \"not spam\",\n",
    "  \"59\": \"not spam\",\n",
    "  \"7\": \"not spam\",\n",
    "  \"8\": \"spam\",\n",
    "  \"9\": \"spam\",\n",
    "  \"10\": \"not spam\",\n",
    "  \"11\": \"spam\",\n",
    "  \"12\": \"spam\",\n",
    "  \"13\": \"not spam\",\n",
    "  \"14\": \"not spam\"\n",
    "}\n",
    "\n",
    "# What's the accuracy?\n",
    "\n",
    "print(f\"Accuracy: {get_accuracy(response, dataset, range(7,15)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the messages that were misclassified, if you have any\n",
    "\n",
    "\n",
    "def print_misclassified_messages(response, dataset):\n",
    "    for entry_number, prediction in response.items():\n",
    "        label_id = dataset[int(entry_number)][\"label\"]\n",
    "        label = id2label[label_id]\n",
    "\n",
    "        if prediction.lower() != label.lower():\n",
    "            sms = dataset[int(entry_number)][\"sms\"]\n",
    "            print(\"---\")\n",
    "            print(f\"Message: {sms}\")\n",
    "            print(f\"Label: {label}\")\n",
    "            print(f\"Prediction: {prediction}\")\n",
    "\n",
    "\n",
    "print_misclassified_messages(response, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN the following on \n",
    "\n",
    "## BERT sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets and transformers packages\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the train and test splits of the imdb dataset\n",
    "splits = [\"train\", \"test\"]\n",
    "ds = {split: ds for split, ds in zip(splits, load_dataset(\"imdb\", split=splits))}\n",
    "\n",
    "# Thin out the dataset to make it run faster for this example\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(500))\n",
    "\n",
    "# Show the dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your code that constructs a query to send to the LLM\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Preprocess the imdb dataset by returning tokenized examples.\"\"\"\n",
    "    return tokenizer(examples['text'])\n",
    "\n",
    "\n",
    "tokenized_ds = {}\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "# Check that we tokenized the examples properly\n",
    "assert tokenized_ds[\"train\"][0][\"input_ids\"][:5] == [101, 2045, 2003, 2053, 7189]\n",
    "\n",
    "# Show the first example of the tokenized training set\n",
    "print(tokenized_ds[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your code freezes the base model\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},  # For converting predictions to strings\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
    ")\n",
    "\n",
    "# Freeze all the parameters of the base model\n",
    "# Hint: Check the documentation at https://huggingface.co/transformers/v4.2.2/training.html\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your DataCollatorWithPadding argument(s)\n",
    "\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis\",\n",
    "        learning_rate=2e-3,\n",
    "        # Reduce the batch size if you don't have enough memory\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer,max_length=512),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the performance of the model on the test set\n",
    "# What do you think the evaluation accuracy will be?\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(tokenized_ds[\"test\"])\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "# Replace <br /> tags in the text with spaces\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "# Add the model predictions to the dataframe\n",
    "predictions = trainer.predict(tokenized_ds[\"test\"])\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show full cell output\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "df[df[\"label\"] != df[\"predicted_label\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Fine-Tuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sms_spam dataset\n",
    "# See: https://huggingface.co/datasets/sms_spam\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# The sms_spam dataset only has a train split, so we use the train_test_split method to split it into train and test\n",
    "dataset = load_dataset(\"sms_spam\", split=\"train\").train_test_split(\n",
    "    test_size=0.2, shuffle=True, seed=23\n",
    ")\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# View the dataset characteristics\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sms': 'Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE. KEEP UR SAME NUMBER, Get extra free mins/texts. Text YES for a call\\n',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first example. Do you think this is spam or not?\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4459/4459 [00:00<00:00, 6814.40 examples/s]\n",
      "Map: 100%|██████████| 1115/1115 [00:00<00:00, 12027.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Let's use a lambda function to tokenize all the examples\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"sms\"], truncation=True), batched=True\n",
    "    )\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with the code to unfreeze all the model parameters\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")\n",
    "\n",
    "# Unfreeze all the model parameters.\n",
    "# Hint: Check the documentation at https://huggingface.co/transformers/v4.2.2/training.html\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with the Training Arguments of your choice\n",
    "\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/spam_not_spam\",\n",
    "        # Set the learning rate\n",
    "        learning_rate = 0.001,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size = 30,\n",
    "        per_device_eval_batch_size = 30,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        eval_strategy  = 'epoch',\n",
    "        save_strategy = 'epoch',\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with the predictions and the text and the labels\n",
    "import pandas as pd\n",
    "\n",
    "items_for_manual_review = tokenized_dataset[\"test\"].select(\n",
    "    [0, 1, 22, 31, 43, 292, 448, 487]\n",
    ")\n",
    "\n",
    "results = trainer.predict(items_for_manual_review)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"sms\": [item[\"sms\"] for item in items_for_manual_review],\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU cells end here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
