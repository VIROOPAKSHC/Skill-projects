{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.28.1 regex-2024.11.6 safetensors-0.5.2 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.48.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0914,  0.2028,  0.0642,  ..., -0.2096,  0.3408,  0.3610],\n",
       "         [ 0.7043,  0.1559,  0.6671,  ..., -0.1631,  0.6102, -0.0539],\n",
       "         [ 0.3537, -0.2293,  0.4000,  ..., -0.0969, -0.1245,  0.2360],\n",
       "         ...,\n",
       "         [-0.1196, -0.3986,  0.1687,  ..., -0.1041, -0.1267,  0.0514],\n",
       "         [-0.4136, -0.2450, -0.6810,  ...,  0.0984, -0.0072, -0.2451],\n",
       "         [ 0.6352, -0.1047, -0.2872,  ...,  0.0797, -0.5590, -0.3174]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8930, -0.4210, -0.7751,  0.7926,  0.5809, -0.3196,  0.8631,  0.3668,\n",
       "         -0.6302, -1.0000, -0.1894,  0.8483,  0.9835,  0.3226,  0.9504, -0.5861,\n",
       "         -0.2958, -0.6697,  0.3723, -0.4195,  0.6984,  0.9999,  0.2713,  0.3164,\n",
       "          0.4406,  0.9726, -0.7934,  0.9501,  0.9498,  0.5037, -0.6986,  0.1608,\n",
       "         -0.9880, -0.3067, -0.8685, -0.9930,  0.3959, -0.7337, -0.0986,  0.0642,\n",
       "         -0.9202,  0.3619,  0.9999, -0.4705,  0.3076, -0.3349, -1.0000,  0.2905,\n",
       "         -0.8739,  0.7012,  0.7005,  0.5922,  0.1948,  0.4732,  0.4622,  0.1156,\n",
       "         -0.0919,  0.1139, -0.3484, -0.6294, -0.5982,  0.4746, -0.7368, -0.9007,\n",
       "          0.6978,  0.6778, -0.0965, -0.2688, -0.2179, -0.1285,  0.8646,  0.3237,\n",
       "          0.3110, -0.8944,  0.3997,  0.2928, -0.6900,  1.0000, -0.5067, -0.9788,\n",
       "          0.8389,  0.6658,  0.5807, -0.1107,  0.3265, -1.0000,  0.5294, -0.0596,\n",
       "         -0.9912,  0.2429,  0.6091, -0.2704,  0.5609,  0.6472, -0.6423, -0.4556,\n",
       "         -0.3615, -0.7385, -0.3293, -0.2252,  0.1645, -0.2932, -0.4256, -0.4502,\n",
       "          0.2099, -0.4700, -0.5737,  0.2254,  0.0377,  0.6787,  0.4850, -0.4267,\n",
       "          0.3992, -0.9611,  0.6473, -0.3521, -0.9829, -0.6023, -0.9893,  0.7025,\n",
       "         -0.2861, -0.2980,  0.9619,  0.0989,  0.4833, -0.0973, -0.8064, -1.0000,\n",
       "         -0.5985, -0.5065, -0.0885, -0.2427, -0.9783, -0.9606,  0.6658,  0.9546,\n",
       "          0.2678,  0.9998, -0.3362,  0.9514, -0.2447, -0.4969,  0.4527, -0.5072,\n",
       "          0.7389,  0.2581, -0.6862,  0.1747, -0.1480,  0.3587, -0.5620, -0.2676,\n",
       "         -0.6241, -0.9473, -0.4091,  0.9487, -0.5013, -0.8454,  0.2285, -0.2419,\n",
       "         -0.4938,  0.8234,  0.7033,  0.3819, -0.3406,  0.4288,  0.2980,  0.5107,\n",
       "         -0.7715, -0.0858,  0.5253, -0.2928, -0.7215, -0.9807, -0.3185,  0.3966,\n",
       "          0.9889,  0.6923,  0.3343,  0.5970, -0.3166,  0.6550, -0.9650,  0.9832,\n",
       "         -0.2798,  0.3266, -0.1753,  0.4190, -0.8337,  0.0171,  0.7826, -0.5763,\n",
       "         -0.7688, -0.0286, -0.5244, -0.4560, -0.6927,  0.3896, -0.3274, -0.4776,\n",
       "         -0.1366,  0.9392,  0.9698,  0.6892, -0.1291,  0.6403, -0.9180, -0.4465,\n",
       "          0.0782,  0.2565,  0.2548,  0.9930, -0.6837, -0.1914, -0.9407, -0.9894,\n",
       "         -0.0338, -0.8935, -0.1562, -0.6299,  0.5643, -0.0691,  0.4647,  0.5176,\n",
       "         -0.9864, -0.7729,  0.3598, -0.4965,  0.5150, -0.3222,  0.8099,  0.8456,\n",
       "         -0.4601,  0.7443,  0.9228, -0.8606, -0.7120,  0.8119, -0.2733,  0.8322,\n",
       "         -0.6712,  0.9876,  0.8334,  0.8335, -0.9333, -0.7141, -0.8152, -0.6722,\n",
       "         -0.1754, -0.0431,  0.7792,  0.6355,  0.3621,  0.4316, -0.5754,  0.9962,\n",
       "         -0.8753, -0.9585, -0.5631, -0.1616, -0.9863,  0.7917,  0.3956,  0.1954,\n",
       "         -0.4214, -0.6294, -0.9702,  0.8496,  0.1400,  0.9836, -0.2596, -0.9261,\n",
       "         -0.5123, -0.9197, -0.1295, -0.2229, -0.0671, -0.2235, -0.9544,  0.5072,\n",
       "          0.4481,  0.5730, -0.6435,  0.9984,  1.0000,  0.9692,  0.8844,  0.9398,\n",
       "         -0.9992, -0.5541,  1.0000, -0.9793, -1.0000, -0.9293, -0.6445,  0.3129,\n",
       "         -1.0000, -0.1881,  0.0013, -0.9093,  0.4045,  0.9773,  0.9925, -1.0000,\n",
       "          0.7938,  0.9174, -0.6831,  0.9018, -0.3732,  0.9742,  0.6446,  0.3782,\n",
       "         -0.3338,  0.5168, -0.9074, -0.8396, -0.4189, -0.6365,  0.9927,  0.1297,\n",
       "         -0.7484, -0.9251,  0.3396, -0.0915, -0.0618, -0.9695, -0.2257,  0.4642,\n",
       "          0.8019,  0.1194,  0.3243, -0.6546,  0.3037, -0.3285,  0.4259,  0.7093,\n",
       "         -0.9551, -0.5453,  0.2867, -0.3830, -0.5130, -0.9671,  0.9687, -0.4941,\n",
       "          0.7370,  1.0000, -0.0101, -0.8998,  0.7126,  0.3828, -0.3608,  1.0000,\n",
       "          0.7509, -0.9777, -0.5978,  0.6191, -0.6117, -0.6052,  0.9994, -0.2416,\n",
       "         -0.4231, -0.1357,  0.9805, -0.9857,  0.9894, -0.9032, -0.9703,  0.9748,\n",
       "          0.9455, -0.5869, -0.5924,  0.1747, -0.6141,  0.3237, -0.9332,  0.7280,\n",
       "          0.5296, -0.1294,  0.8985, -0.7144, -0.6202,  0.3463, -0.5606,  0.0403,\n",
       "          0.9188,  0.5536, -0.2875,  0.0309, -0.3412, -0.5581, -0.9790,  0.3526,\n",
       "          1.0000, -0.0866,  0.6206, -0.5501, -0.0593, -0.2180,  0.4712,  0.5768,\n",
       "         -0.3436, -0.8611,  0.4788, -0.9445, -0.9867,  0.7513,  0.2403, -0.3396,\n",
       "          1.0000,  0.5474,  0.1826,  0.2855,  0.9257,  0.0974,  0.6244,  0.7338,\n",
       "          0.9763, -0.2864,  0.6233,  0.7971, -0.7827, -0.4138, -0.6997,  0.1254,\n",
       "         -0.9298, -0.0425, -0.9399,  0.9624,  0.7952,  0.3755,  0.2741,  0.5190,\n",
       "          1.0000, -0.5902,  0.6571, -0.0865,  0.8284, -0.9988, -0.8122, -0.3954,\n",
       "         -0.0844, -0.7160, -0.3769,  0.2957, -0.9563,  0.5710,  0.4131, -0.9884,\n",
       "         -0.9901,  0.1609,  0.7616,  0.1582, -0.9586, -0.7438, -0.5460,  0.5126,\n",
       "         -0.2413, -0.9404,  0.0150, -0.3478,  0.4868, -0.2398,  0.6647,  0.7635,\n",
       "          0.6792, -0.4106, -0.3107, -0.1309, -0.7957,  0.8041, -0.7845, -0.8474,\n",
       "         -0.2580,  1.0000, -0.5045,  0.7568,  0.6684,  0.6788, -0.1549,  0.2157,\n",
       "          0.8790,  0.3530, -0.5835, -0.5573, -0.4093, -0.4591,  0.5549,  0.3677,\n",
       "          0.6247,  0.8200,  0.6979,  0.0200, -0.0350,  0.0569,  0.9994, -0.2281,\n",
       "         -0.2038, -0.3509,  0.0857, -0.4395, -0.4338,  1.0000,  0.2968,  0.3433,\n",
       "         -0.9901, -0.8044, -0.9094,  1.0000,  0.8468, -0.7394,  0.6705,  0.5291,\n",
       "         -0.0829,  0.7353, -0.2154, -0.3104,  0.2639,  0.1450,  0.9561, -0.5495,\n",
       "         -0.9690, -0.5776,  0.4146, -0.9682,  0.9997, -0.5743, -0.2903, -0.3984,\n",
       "         -0.1650,  0.1174, -0.0231, -0.9824, -0.2188,  0.1964,  0.9607,  0.3029,\n",
       "         -0.6611, -0.8682,  0.4533,  0.6521, -0.8307, -0.9557,  0.9743, -0.9881,\n",
       "          0.5533,  1.0000,  0.2436, -0.4990,  0.3017, -0.3844,  0.3742, -0.3193,\n",
       "          0.6246, -0.9750, -0.3870, -0.2255,  0.2851, -0.1489, -0.3097,  0.6789,\n",
       "          0.1714, -0.6043, -0.7041, -0.1322,  0.4579,  0.8296, -0.2989, -0.1616,\n",
       "          0.0716, -0.1951, -0.9392, -0.2910, -0.4967, -1.0000,  0.6324, -1.0000,\n",
       "          0.3762,  0.0368, -0.2556,  0.7880,  0.4616,  0.5591, -0.7260, -0.5336,\n",
       "          0.6388,  0.7957, -0.4367, -0.1007, -0.6115,  0.3764, -0.1624,  0.3175,\n",
       "         -0.3791,  0.7289, -0.2463,  1.0000,  0.1840, -0.5594, -0.9689,  0.2092,\n",
       "         -0.3516,  1.0000, -0.8349, -0.9563,  0.4861, -0.6578, -0.8672,  0.3715,\n",
       "          0.0298, -0.7731, -0.9283,  0.9644,  0.8188, -0.6412,  0.5930, -0.3375,\n",
       "         -0.4821,  0.1076,  0.6677,  0.9884,  0.5803,  0.8693, -0.1518, -0.4029,\n",
       "          0.9692,  0.2754,  0.2668,  0.1209,  1.0000,  0.3928, -0.9268,  0.2109,\n",
       "         -0.9783, -0.2809, -0.9541,  0.3632,  0.3070,  0.8688, -0.2886,  0.9551,\n",
       "         -0.5858,  0.0543, -0.3115, -0.1966,  0.4186, -0.9247, -0.9837, -0.9848,\n",
       "          0.5341, -0.4816, -0.1397,  0.2388,  0.1097,  0.3948,  0.5044, -1.0000,\n",
       "          0.9360,  0.4209,  0.7859,  0.9670,  0.8064,  0.3681,  0.2389, -0.9825,\n",
       "         -0.9817, -0.3671, -0.2433,  0.7797,  0.5904,  0.8985,  0.3833, -0.4433,\n",
       "         -0.4133, -0.3902, -0.7655, -0.9929,  0.5202, -0.2417, -0.9471,  0.9572,\n",
       "         -0.1267, -0.0981,  0.0430, -0.6678,  0.9070,  0.8043,  0.4296,  0.1630,\n",
       "          0.3388,  0.8918,  0.9397,  0.9853, -0.7101,  0.7907, -0.4703,  0.5472,\n",
       "          0.7396, -0.9397,  0.1014,  0.4387, -0.3335,  0.2748, -0.1912, -0.9713,\n",
       "          0.3639, -0.2856,  0.5473, -0.4861,  0.0496, -0.4185, -0.1387, -0.6539,\n",
       "         -0.7205,  0.6929,  0.2752,  0.8743,  0.7857, -0.0360, -0.6206, -0.1593,\n",
       "         -0.6194, -0.9235,  0.9244, -0.0820, -0.2213,  0.3502, -0.0015,  0.7778,\n",
       "          0.0587, -0.2991, -0.3293, -0.6134,  0.8740, -0.3878, -0.6034, -0.5177,\n",
       "          0.7027,  0.2976,  0.9999, -0.7045, -0.7451, -0.2873, -0.3546,  0.4885,\n",
       "         -0.5178, -1.0000,  0.3898, -0.2438,  0.6129, -0.5179,  0.7723, -0.3821,\n",
       "         -0.9806, -0.3285,  0.3961,  0.5536, -0.5382, -0.3978,  0.6504,  0.4235,\n",
       "          0.9420,  0.8670,  0.0482,  0.2304,  0.7071, -0.4014, -0.7193,  0.9189]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenizer(\"Hi I want to go there\",return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
